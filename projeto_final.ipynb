{
  "metadata": {
    "name": "Note converted from Jupyter_2GS9YJ3H9",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nsc"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark \nrdd \u003d sc.textFile(\u0027s3://megadados-alunos/dados/all_reviews_clean_tsv/\u0027).cache()"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd.take(1)\n\nheader \u003d rdd.first()\ntemp_var \u003d rdd.map(lambda k: k.split(\"\\t\"))\nlog_df\u003dtemp_var.toDF(header.split(\"\\t\"))\nlog_df.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark \n# Quantos reviews existem?\n\nrdd.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark \n# Quantos clientes existem?\n\nrdd_clientes \u003d rdd.map(lambda x: x.split(\u0027\\t\u0027)) \\\n                    .map(lambda x: (x[1],1)) \\\n                    .reduceByKey(lambda x, y: x+y) \\\n                    .cache()"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark \nrdd_clientes.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Quantos produtos existem?\n\nrdd_produtos \u003d rdd.map(lambda x: x.split(\u0027\\t\u0027)) \\\n                    .map(lambda x: (x[3],1)) \\\n                    .reduceByKey(lambda x, y: x+y) \\\n                    .cache()"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd_produtos.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark \nrdd_clientes.takeOrdered(5, lambda x: -x[1])"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Quantos reviews existem para cada “star_rating” (de 1 a 5 estrelas)? \n\nrdd_stars \u003d rdd.map(lambda x: x.split(\u0027\\t\u0027)) \\\n                    .map(lambda x: (x[7],1)) \\\n                    .reduceByKey(lambda x, y: x+y) \\\n                    .cache()"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd_stars.takeOrdered(5)"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Item desafio: Quais os 10 produtos que receberam maior rating médio dentre os produtos com \n# mais de 10 ratings, e considerando apenas os ratings de clientes que só deram um review ao todo? \n\nrdd_clientes_1_review \u003d rdd_clientes.filter(lambda x: (x[1]\u003d\u003d1))\nclients_1 \u003d rdd_clientes_1_review.keys().collect()"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nclients_1[:10]"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nlen(clients_1)"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql import SparkSession\nspark \u003d SparkSession.builder.appName(\u0027ReviewsClassifier\u0027).getOrCreate()# Load data and rename column\ndf \u003d spark.read.option(\"header\", \"false\") \\\n    .option(\"delimiter\", \"\\t\") \\\n    .option(\"inferSchema\", \"true\") \\\n    .csv(\"s3://megadados-alunos/dados/all_reviews_clean_tsv/\") "
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%python\nBOTS"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%pyspark\nhist \u003d rdd_clientes.map(lambda x: x[1]).histogram(100)\nlen(hist)"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nhist[0]"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nhist[1]"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%pyspark\n# Quantos bots existem? \n\nbots  \u003d rdd_clientes.filter(lambda x: (x[1]\u003ehist[0][1]))"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nbots.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%pyspark\nbots.take(5)"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nlist_ids_bots \u003d bots.map(lambda x : x[0]).collect()"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nlist_ids_bots"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd_bots \u003d rdd.map(lambda x: x.split(\u0027\\t\u0027)) \\\n.filter(lambda x: x[1] in list_ids_bots)\\\n.map(lambda x: (x[1],x[10],x[6],x[7],x[9])) \\\n.cache()\n\n\nrdd_bots.take(2)"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd_bots.count()"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n# Para qual tipo de produto eles fazem review? \n\nrdd_bots_product_type \u003d rdd_bots.map(lambda x: (x[2],1)) \\\n                    .reduceByKey(lambda x, y: x+y) \\\n                    .cache()\nrdd_bots_product_type.collect()"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd_bots_product_type.takeOrdered(100, key\u003dlambda x: -x[1])"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n# Os reviews são em sua maioria positivos ou negativos? \n\nrdd_bots_reviews \u003d rdd_bots.map(lambda x: (x[3],1)) \\\n                    .reduceByKey(lambda x, y: x+y) \\\n                    .cache()\n                    \nrdd_bots_reviews.takeOrdered(100, key\u003dlambda x: -x[1])"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n# Os reviews dos bots recebem votes? Se sim, muitos ou poucos? \n\nrdd_bots_votes\u003d rdd_bots.map(lambda x: (x[4],1)) \\\n                    .reduceByKey(lambda x, y: x+y) \\\n                    .cache()\n                    \nrdd_bots_votes.takeOrdered(100, key\u003dlambda x: -x[1])"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nzero_votes \u003d rdd_bots_votes.filter(lambda x: (int(x[0])\u003c1))"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n1-(zero_votes.values().sum() / rdd_bots_votes.values().sum())"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfew_votes \u003d rdd_bots_votes.filter(lambda x: (0\u003cint(x[0])\u003c10))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%pyspark\n1 - ((few_votes.values().sum() / rdd_bots_votes.values().sum()) / (1-(zero_votes.values().sum() / rdd_bots_votes.values().sum())))"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd_bots_helpful \u003d rdd_bots.map(lambda x: (x[1],1)) \\\n                    .reduceByKey(lambda x, y: x+y) \\\n                    .cache()\n                    \nrdd_bots_helpful.takeOrdered(100, key\u003dlambda x: -x[1])"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n2329762/(2329762+203402)"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Os votes dos bots são classificados como úteis? \n\nrdd_bots_votes\u003d rdd_bots.map(lambda x: (x[4],1)).count()"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd_bots_votes \u003d rdd_bots.map(lambda x: int(x[4])).histogram(10)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd_bots_votes[1]"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd_bots_votes[0]"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nrdd.take(1)\n\nheader \u003d rdd.filter(lambda x: (x[13],x[7]) ).first()\n\ntemp_var \u003d rdd.map(lambda k: k.split(\"\\t\")).filter(lambda x: (x[13],x[7]) )\ntemp_var.take(1)\n\nlog_df\u003dtemp_var.toDF(temp_var.first())\nlog_df.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "NAIVE BAYES"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql import SparkSession\nspark \u003d SparkSession.builder.appName(\u0027ReviewsClassifier\u0027).getOrCreate()# Load data and rename column\ndf \u003d spark.read.option(\"header\", \"false\") \\\n    .option(\"delimiter\", \"\\t\") \\\n    .option(\"inferSchema\", \"true\") \\\n    .csv(\"s3://megadados-alunos/dados/all_reviews_clean_tsv/\") "
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql.functions import lit\nfrom pyspark.sql.functions import when\ndf_new \u003d df.withColumn(\"label_string\", \\\n   when((df[7] \u003c\u003d 3), lit(\"R\")) \\\n     .when((df[7] \u003d\u003d 4) , lit(\"N\")) \\\n     .otherwise(lit(\"B\")) \\\n  )"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_new"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Import the required packages\nfrom pyspark.ml.feature import CountVectorizer\nfrom pyspark.ml.feature import Tokenizer, RegexTokenizer\nfrom pyspark.ml.feature import StringIndexer\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import NaiveBayes\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n\n\nstages \u003d []\n# 1. clean data and tokenize sentences using RegexTokenizer\nregexTokenizer \u003d RegexTokenizer(inputCol\u003d\"_c13\", outputCol\u003d\"tokens\", pattern\u003d\"\\\\W+\")\nstages +\u003d [regexTokenizer]\n\n# 2. CountVectorize the data\ncv \u003d CountVectorizer(inputCol\u003d\"tokens\", outputCol\u003d\"token_features\", minDF\u003d2.0)#, vocabSize\u003d3, minDF\u003d2.0\nstages +\u003d [cv]\n\n# 3. Convert the labels to numerical values using binariser\nindexer \u003d StringIndexer(inputCol\u003d\"label_string\", outputCol\u003d\"label\")\nstages +\u003d [indexer]\n\n# 4. Vectorise features using vectorassembler\nvecAssembler \u003d VectorAssembler(inputCols\u003d[\u0027token_features\u0027], outputCol\u003d\"features\")\nstages +\u003d [vecAssembler]\n\n# [print(\u0027\\n\u0027, stage) for stage in stages]\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nstages"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_new \u003d df_new.na.drop()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf_new\n"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n\nfrom pyspark.ml import Pipeline\npipeline \u003d Pipeline(stages\u003dstages)\ndata \u003d pipeline.fit(df_new).transform(df_new)\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ntrain, test \u003d data.randomSplit([0.7, 0.3], seed \u003d 2018)"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.ml.classification import NaiveBayes# Initialise the model\nnb \u003d NaiveBayes(smoothing\u003d1.0, modelType\u003d\"multinomial\")# Fit the model\nmodel \u003d nb.fit(train)# Make predictions on test data\npredictions \u003d model.transform(test)\npredictions.select(\"label\", \"prediction\", \"probability\").show()"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\nevaluator \u003d BinaryClassificationEvaluator(rawPredictionCol\u003d\"prediction\")\naccuracy \u003d evaluator.evaluate(predictions)\nprint (\"Model Accuracy: \", accuracy)"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n## Melhorando o modelo \n\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n# Create ParamGrid and Evaluator for Cross Validation\nparamGrid \u003d ParamGridBuilder().addGrid(nb.smoothing, [1.0, 2.0]).build()\ncvEvaluator \u003d BinaryClassificationEvaluator(rawPredictionCol\u003d\"rawPrediction\")\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Run Cross-validation\ncv \u003d CrossValidator(estimator\u003dnb, estimatorParamMaps\u003dparamGrid, evaluator\u003dcvEvaluator, parallelism\u003d10)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ncvModel \u003d cv.fit(train)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n# Make predictions on testData. cvModel uses the bestModel.\ncvPredictions \u003d cvModel.transform(test)\n\n# Evaluate bestModel found from Cross Validation\nevaluator.evaluate(cvPredictions)"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "\n%pyspark\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nevaluator \u003d MulticlassClassificationEvaluator(labelCol\u003d\"label\", predictionCol\u003d\"prediction\",\n                                              metricName\u003d\"f1-score\")\n\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfrom pyspark.mllib.evaluation import MulticlassMetrics\n# Create (prediction, label) pairs\npredictionAndLabel \u003d cvPredictions.select(\"prediction\", \"label\").rdd\n\n# Generate confusion matrix\nmetrics \u003d MulticlassMetrics(predictionAndLabel)\nprint (metrics.confusionMatrix())\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}